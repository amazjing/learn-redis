**Redis**学习笔记

**学习地址：**

https://www.bilibili.com/video/BV1Rv41177Af?p=2&spm_id_from=pageDriver

**学习大纲：**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/Redis6%E8%AF%BE%E7%A8%8B%E5%A4%A7%E7%BA%B2.png)



## 1.NoSQL数据库简介

### 1.1.技术发展

**技术的分类：**

1. 解决功能性的问题：Java、Jsp、RDBMS、Tomcat、HTML、Linux、JDBC、SVN
2. 解决扩展性的问题：Struts、Spring、SpringMVC、Hibernate、Mybatis
3. 解决性能的问题：**NoSQL**、Java线程、Hadoop、Nginx、MQ、ElasticSearch



#### 1.1.1.Web1.0时代

Web1.0的时代，数据访问量很有限，用一夫当关的高性能的单点服务器可以解决大部分问题。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202101439.png)



#### 1.1.2.Web2.0时代

随着Web2.0的时代的到来，用户访问量大幅度提升，同时产生了大量的用户数据。加上后来的智能移动设备的普及，所有的互联网平台都面临了巨大的性能挑战。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202101440.png)



#### 1.1.3.Nosql解决CPU及内存压力

假如一个客户端访问，可能是一台电脑也可能是一个手机端，而我们的服务器可能是两台也可能是多台。在客户端访问服务器，我们使用了Nginx进行负载均衡，将访问平均分摊到不同服务器中，问题来了，如果用户登录时，是在第一台服务器上，seesion将用户数据保存。下次用户登录时，如果是第二台服务器，而第二台的服务器上seesion没有存储用户信息。如何seesion的共享。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220210144930.png)



**解决方案：**

1. 存储到客户端或者说放在cookie中。好处是每次请求都会带着cookie信息，能保证seesion共享。

   缺点：不安全。

2. session复制。比如在某台服务器保存了session对象信息。将seesion对象再复制到多台服务器上。

   缺点：造成了空间极大的浪费，seesion数据冗余。

3. 使用Nosql数据库。比如用户登录后，将用户信息存储到Nosql数据库中，当用户第二次访问，我们看下Nosql数据库中，有没有信息，有则登录，没有则重新登录。

   优点：缓存数据库，完全在内存中，速度快，数据结构简单。



![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220210150618.png)



#### 1.1.4.Nosql解决IO压力

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220210151132.png)

当一个项目随着时间的推移，我们的数据库中的数据就会越来越多。此时，我们使用原始方案把数据库和表进行水平切分、垂直切分、读写分离等。这些虽然能解决，但是有一个缺点，需要通过破坏一定的业务逻辑来获取性能。这种方式并不是最好的方式，我们可以使用缓存数据库，就是把Nosql做缓存处理。项目中一些频繁的查询数据，可以放到缓存数据库中。项目中的一些特有的数据还可以列式存储、文档存储等等。



### 1.2.NoSQL数据库

#### 1.2.1.NoSQL数据库概述

NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是SQL”，泛指非关系型的数据库。 

NoSQL 不依赖业务逻辑方式存储，而以简单的key-value模式存储。因此大大的增加了数据库的扩展能力。

- 不遵循SQL标准。
- 不支持ACID。
- 远超于SQL的性能。



#### 1.2.2.NoSQL适用场景

- 对数据高并发的读写
- 海量数据的读写
- 对数据高可扩展性的



#### 1.2.3.NoSQL不适用场景

- 需要事务支持
- 基于sql的结构化查询存储，处理复杂的关系,需要即席查询。
- 用不着sql的和用了sql也不行的情况，请考虑用NoSql



#### 1.2.4.Memcache

- 很早出现的NoSql数据库

- 数据都在内存中，一般不持久化

- 支持简单的key-value模式，支持类型单一
- 一般是作为缓存数据库辅助持久化的数据库



#### 1.2.5.Redis

- 几乎覆盖了Memcached的绝大部分功能
- 数据都在内存中，支持持久化，主要用作备份恢复
- 除了支持简单的key-value模式，还支持多种数据结构的存储，比如 list、set、hash、zset等。
- 一般是作为缓存数据库辅助持久化的数据库



#### 1.2.6.MongoDB

- 高性能、开源、模式自由(schema  free)的**文档型数据库**
- 数据都在内存中， 如果内存不足，把不常用的数据保存到硬盘
- 虽然是key-value模式，但是对value（尤其是**json**）提供了丰富的查询功能
- 支持二进制数据及大型对象
- 可以根据数据的特点**替代RDBMS** ，成为独立的数据库。或者配合RDBMS，存储特定的数据



### 1.3.行式存储数据库（大数据时代）

#### 1.3.1.行式数据库

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220210154152.png)

按照之前的关系型数据库Mysql存储数据，就是每条数据都是按照字段分别存储数据。如果是行式数据库，则将图片中的“张三”，“李四”，“王五”分别存储成一部分。



#### 1.3.2.列式数据库

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220210154726.png)



## 2.Redis概述安装

- Redis是一个开源的key-value存储系统。
- 和Memcached类似，它支持存储的value类型相对更多，包括**string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）**。
- 这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。
- 在此基础上，Redis支持各种不同方式的排序。
- 与memcached一样，为了保证效率，数据都是缓存在内存中。
- 区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。
- 并且在此基础上实现了master-slave(主从)同步。



### 2.1.应用场景

#### 2.1.1.配合关系型数据库做高速缓存

- 高频次，热门访问的数据，降低数据库IO

- 分布式架构，做session共享



#### 2.1.2.多样的数据结构存储持久化数据

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220210155935.png)



### 2.2.Redis安装

#### 2.2.1.安装版本

6.2.1 for Linux（redis-6.2.1.tar.gz）

#### 2.2.2.安装步骤

##### 2.2.2.1.准备工作

**下载安装最新版的gcc编译器：安装C 语言的编译环境：**

- yum install centos-release-scl scl-utils-build
- yum install -y devtoolset-8-toolchain
- scl enable devtoolset-8 bash
- 测试 gcc版本 gcc --version



##### 2.2.2.2.安装Redis

下载redis地址：https://redis.io/ ，再**Download it**点击链接进行下载（我使用的是课件的版本，看自己情况选择）

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220211093441.png)



1. 下载redis-6.2.1.tar.gz放/opt目录
2. 解压命令：`tar -zxvf redis-6.2.1.tar.gz`
3. 解压完成后进入目录：`cd redis-6.2.1`
4. 在redis-6.2.1目录下再次执行`make`命令（只是编译好）
4. 跳过make test 继续执行: `make install`



**如果没有准备好C语言编译环境，make 会报错—Jemalloc/jemalloc.h：没有那个文件**

解决方案：

运行`make distclean`

在redis-6.2.1目录下再次执行make命令（只是编译好）

跳过make test 继续执行: `make install`

### 2.3.安装目录文件说明

默认安装目录：/usr/local/bin

目录下文件的作用：

- redis-benchmark：性能测试工具，可以在自己本子运行，看看自己本子性能如何
- redis-check-aof：修复有问题的AOF文件
- redis-check-dump：修复有问题的dump.rdb文件
- redis-sentinel：Redis集群使用
- redis-server：Redis服务器启动命令
- redis-cli：客户端，操作入口



### 2.4.启动Redis

#### 2.4.1.前台启动

使用命令`redis-server`，就可以启动了。**这种方式不推荐！**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220211085934.png)

这种启动方式会出现关闭窗口后，redis服务停止。



#### 2.4.2.后台启动

**步骤：**

1. 备份redis.conf

   在Redis目录下，复制redis.conf文件到/opt/local/redis文件夹下。使用命令`cp redis.conf /usr/local/redis/redis.conf`

2. 将备份的redis.conf文件，进行编辑，将**daemonize no**改成**yes**

3. 在redis的安装目录下使用命令`redis-server /usr/local/redis/redis.conf`

4. 通过指令查看进程确定redis是否已启动。`ps -ef | grep redis`

**以后使用Redis，进入/usr/local/redis目录下，直接使用`redis-server /usr/local/redis/redis.conf`,然后再使用`redis-cli`即可后台启动成功。**



#### 2.4.3.访问Redis

使用指令`redis-cli`就可以进入redis了。

进入redis后，使用`ping`命令，如果显示PONG则说明redis正常。



#### 2.4.4.关闭Redis

使用指令`shutdown`关闭redis

也可以使用查找redis进程号后，杀死redis进程进行关闭redis。

获取进程号`ps -ef | grep redis`，再使用`kill -9 进程号`杀死进程。



### 2.5.Redis相关知识

1. 默认16个数据库，类似数组下标从0开始，初始默认使用0号库
2. 使用命令 select  <dbid>来切换数据库。如: select 8
3. 统一密码管理，所有库同样密码。
4. `dbsize`查看当前数据库的key的数量
5. `flushdb`清空当前库
6. `flushall`通杀全部库

**Redis是单线程+多路IO复用技术**

**解释：**

比如有三个人要去火车站买票，这三个人分别去上海、深圳、广州。

他们三个人都让黄牛去买票，黄牛在买票的同时，这三个人可以继续做自己的事情，等到黄牛买到某张票时，就会通知某个人进行取票。这就是Redis的单线程+多路IO复用技术。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220211101038.png)



多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池）



## 3.常用五大数据类型

Redis官网数据类型操作指令：http://www.redis.cn/commands.html

### 3.1.Redis键(key)

| Keys键          | 说明                                                         |
| --------------- | ------------------------------------------------------------ |
| set <key value> | 输入key与value，存储数据                                     |
| get <key>       | 根据key键获取value值                                         |
| keys *          | 查看当前库所有key (匹配：keys *1)                            |
| exists <key>    | 判断某个key是否存在；存在返回1，不存在返回0                  |
| type <key>      | 查看key是什么类型                                            |
| del <key>       | 删除指定的key数据，立即删除                                  |
| unlink <key>    | 根据value选择非阻塞删除。仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。非立即删除。 |
| expire <key 10> | 为给定的key设置过期时间为10秒钟                              |
| ttl <key>       | 查看还有多少秒过期，-1表示永不过期，-2表示已过期             |
| select          | 命令切换数据库                                               |
| dbsize          | 查看当前数据库的key的数量                                    |
| flushdb         | 清空当前库                                                   |
| flushall        | 通杀全部库                                                   |



### 3.2.Redis字符串(String)

#### 3.2.1.简介

- String是Redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。
- String类型是**二进制安全**的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象。
- String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M。



#### 3.2.2.常用命令

| keys键                              | 说明                                                         |
| ----------------------------------- | ------------------------------------------------------------ |
| set  <key><value>                   | 添加键值对                                                   |
| get  <key>                          | 查询对应键值                                                 |
| append  <key><value>                | 给定的<value> 追加到原值的末尾                               |
| strlen  <key>                       | 获得值的长度                                                 |
| setnx  <key><value>                 | 只有在 key 不存在时,设置 key 的值。如果存在不能设置成功，返回0，反之返回1 |
| incr  <key>                         | 将 key 中储存的数字值增1，只能对数字值操作，如果为空，新增值为1 |
| decr  <key>                         | 将 key 中储存的数字值减1，只能对数字值操作，如果为空，新增值为-1 |
| incrby  <key><步长>                 | 将 key 中储存的数字值增加。自定义步长。                      |
| decrby <key><步长>                  | 将 key 中储存的数字值减少。自定义步长。                      |
| mset  <key1><value1><key2><value2>  | 同时设置一个或多个 key-value对                               |
| mget  <key1><key2><key3>            | 同时获取一个或多个 value                                     |
| msetnx <key1><value1><key2><value2> | 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。 |
| getrange  <key><起始位置><结束位置> | 获得值的范围，类似java中的substring，前包，后包              |
| setrange  <key><起始位置><value>    | 用 <value>  覆写<key>所储存的字符串值，从<起始位置>开始(索引从0开始) |
| setex  <key><过期时间><value>       | 设置键值的同时，设置过期时间，单位秒。                       |
| getset <key><value>                 | 以新换旧，设置了新值同时获得旧值。                           |



在使用INCR <key>时，有原子性操作。

所谓**原子**操作是指不会被线程调度机制打断的操作；

这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。

1. 在单线程中， 能够在单条指令中完成的操作都可以认为是"原子操作"，因为中断只能发生于指令之间。
2. 在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。

Redis单命令的原子性主要得益于Redis的单线程。

**案例：**

java中的i++是否是原子操作？

**不是**，因为java是一个多线程，里面的过程中会互相干扰到。

i=0;两个线程分别对i进行++100次,值是多少？

值是不固定的，范围在**2~200**之间。原因是不确定哪个线程限制性，再执行过程中，存在线程之间互相打断的情况。比如执行有a、b两个线程在执行i++操作，a执行到i=99，突然被b线程打断了，b线程进行i++操作，b线程执行到i=1时，可能还会被a线程打断。



同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。

**原子性，有一个失败则都失败**



#### 3.2.3.数据结构

String的数据结构为简单动态字符串(Simple Dynamic String,缩写SDS)。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202141438.png)

如图中所示，内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。



### 3.3.Redis列表(List)

#### 3.3.1.简介

单键多值

Redis 列表是简单的字符串列表，按照插入顺序排序。我们可以在其头部(left)和尾部(right)添加新的元素。在插入时，如果该键并不存在，Redis将为该键创建一个新的链表。如果链表中所有的元素均被移除，那么该键也将会被从数据库中删除。List中可以包含的最大元素数量是 4294967295。

从元素插入和删除的效率视角来看，如果我们是在链表的两头插入或删除元素，这将 会是非常高效的操作，即使链表中已经存储了百万条记录，该操作也可以在常量时间内完成。然而需要说明的是，**如果元素插入或删除操作是作用于链表中间，那将会是非常低效的。**

它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202141440.png)

**List元素的下表从0开始**



#### 3.3.2.常用命令

| keys键                                 | 说明                                                         |
| -------------------------------------- | ------------------------------------------------------------ |
| lpush<key><value1><value2><value3>     | 从左边插入一个或多个值                                       |
| rpush<key><value1><value2><value3>     | 从右边插入一个或多个值                                       |
| lpop<key>                              | 从左边吐出一个值。值在键在，值光键亡(取出某个下标的值后，该值就不存在了) |
| rpop  <key>                            | 从右边吐出一个值。值在键在，值光键亡(取出某个下标的值后，该值就不存在了) |
| rpoplpush  <key1><key2>                | 从<key1>列表右边吐出一个值，插到<key2>列表左边；<key1>吐出的值在<key1>就不存在了 |
| lrange <key><start><stop>              | 按照索引下标获得元素(从左到右)；其中 0 表示列表的第一个元素， 1 表示列表的第二个元素，以此类推。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。(0 -1表示获取所有值)<br />取值时，会按照从后到前的顺序显示；例如：先存的是v1、v2、v3。取出的值是显示v3、v2、v1 |
| lindex <key><index>                    | 按照索引下标获得元素(从左到右)                               |
| llen <key>                             | 获得列表长度                                                 |
| linsert <key> before <value><newvalue> | 在指定的<key>的<value>前面新增加一个<value>；例如：k2的值为v1、v2、v3，使用LINSERT k2 before "v1" "newv11"，那么，k2的值为v11、v1、v2、v3 |
| linsert <key> after<value><newvalue>   | 在指定的<key>的<value>后面新增加一个<value>；例如：k2的值为v1、v2、v3，使用LINSERT k2 after "v1" "newv11"，那么，k2的值为v1、newv11、v2、v3 |
| lrem <key> <n> <value>                 | 从左边删除n个value(从左到右)                                 |
| lset<key><index><value>                | 将列表key下标为index的值替换成value                          |



#### 3.3.3.数据结构

List的数据结构为快速链表quickList。

首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。

它将所有的元素紧挨着一起存储，分配的是一块连续的内存。

当数据量比较多的时候才会改成quicklist。

因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202141535.png)

Redis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。



### 3.4.Redis集合(Set)

#### 3.4.1.简介

在Redis中，我们可以将Set类型看作为**没有排序的字符集合**，和List类型一样，也可以在该类型的数据值上执行添加、删除或判断某一元素是否存在等操作。需要 说明的是，这些操作的时间是常量时间。Set可包含的最大元素数是4294967295。
和List类型不同的是，**Set集合中不允许出现重复的元素**。和List类型相比，Set类型在功能上还存在着一个非常重要的特性，即在服务器端完成多个Sets之间的聚合计 算操作，如unions、intersections和differences（就是交集并集那些了）。由于这些操作均在服务端完成， 因此效率极高，而且也节省了大量的网络IO开销。

Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以**自动排重**的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。

Redis的Set是String类型的无序集合。它底层其实是一个value为null的hash表，所以添加，删除，查找的**复杂度都是O(1)**。

一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变。

**set的方法都以s开头**



#### 3.4.2.常用命令

| keys键                           | 说明                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| sadd <key><value1><value2>       | 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略 |
| smembers <key>                   | 取出该集合的所有值                                           |
| sismember <key><value>           | 判断集合<key>是否为含有该<value>值，有1，没有0               |
| scard<key>                       | 返回该集合的元素个数                                         |
| srem <key><value1><value2>       | 删除集合中的某个元素                                         |
| spop <key>                       | 随机从该集合中吐出一个值；如果值都取完了，那么key就不存在了  |
| srandmember <key><n>             | 随机从该集合中取出n个值。不会从集合中删除                    |
| smove <source><destination>value | 把集合中一个值从一个集合移动到另一个集合                     |
| sinter <key1><key2>              | 返回两个集合的交集元素                                       |
| sunion <key1><key2>              | 返回两个集合的并集元素                                       |
| sdiff <key1><key2>               | 返回两个集合的差集元素(key1中的，不包含key2中的)             |



#### 3.4.3.数据结构

Set数据结构是dict字典，字典是用哈希表实现的。

Java中HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。



### 3.5.Redis哈希(Hash)

#### 3.5.1.简介

Redis hash 是一个键值对集合。

Redis hash是一个String类型的field和value的映射表，hash特别适合用于存储对象。类似Java里面的Map<String,Object>

用户ID为查找的key，存储的value用户对象包含姓名，年龄，生日等信息，如果用普通的key/value结构来存储

主要有以下2种存储方式：

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220214155456.png)



**第一种方式：(不推荐使用)**

将用户信息存成一个对象。user:{id=1,name=zhangsan,age=20}，如果每年需要修改用户的年龄，这种方式存储到redis，需要将{id=1,name=zhangsan,age=20}转换成一个对象，然后将age改为21，再变成json字符串，然后最终存到redis中去。

**第二种方式：(不推荐)**

将数据进行分开存储，格式如图：

这种方式存储缺点数据太分散。

**第三种方式：(推荐)**

好处存储比较方便，取值改值都比较方便

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/200220214195955.png)



#### 3.5.2.常用命令

| keys键                                       | 说明                                                         |
| -------------------------------------------- | ------------------------------------------------------------ |
| hset <key><field><value>                     | 给<key>集合中的  <field>键赋值<value>                        |
| hget <key1><field>                           | 从<key1>集合<field>取出 value                                |
| hmset <key1><field1><value1><field2><value2> | 批量设置hash的值                                             |
| hexists<key1><field>                         | 查看哈希表 key 中，给定域 field 是否存在；存在输出1，反之0   |
| hkeys <key>                                  | 列出该hash集合的所有field                                    |
| hvals <key>                                  | 列出该hash集合的所有value                                    |
| hincrby <key><field><increment>              | 为哈希表 key 中的域 field 的值加上增量 1  -1                 |
| hsetnx <key><field><value>                   | 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 |



#### 3.5.3.数据结构

Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。



### 3.6.Redis有序集合Zset(sorted set) 

#### 3.6.1.简介

Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。

不同之处是有序集合的每个成员都关联了一个评分(score),这个评分(score)被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。

因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。

访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。



#### 3.6.2.常用命令

| keys键                                                       | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| zadd  <key><score1><value1><score2><value2>                  | 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 |
| zrange <key><start><stop>  [WITHSCORES]                      | 返回有序集 key 中，下标在<start><stop>之间的元素带WITHSCORES，可以让分数一起和值返回到结果集 |
| zrangebyscore <key> minmax [withscores] [limit offset count] | 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 |
| zrevrangebyscore <key> maxmin [withscores] [limit offset count] | 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从大到小)次序排列。 |
| zincrby <key><increment><value>                              | 为元素的score加上增量                                        |
| zrem  <key><value>                                           | 删除该集合下，指定值的元素                                   |
| zcount <key><min><max>                                       | 统计该集合，分数区间内的元素个数                             |
| zrank <key><value>                                           | 返回该值在集合中的排名，从0开始。                            |

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220214210231.png)



**案例：如何利用zset实现一个文章访问量的排行榜？**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220214143811.png)



#### 3.6.3.数据结构

SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map<String, Double>，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。

zset底层使用了两个数据结构

1. **hash**，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。
2. **跳跃表**，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。



#### 3.6.4.跳跃表（跳表）

1. **简介**

有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。



2. **实例**

对比有序链表和跳跃表，从链表中查询出51

1. 有序链表

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202142051.png)

   要查找值为51的元素，需要从第一个元素开始依次查找、比较才能找到。共需要6次比较。

2. 跳跃表

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202142053.png)

   从第2层开始，1节点比51节点小，向后比较。

   21节点比51节点小，继续向后比较，后面就是NULL了，所以从21节点向下到第1层

   在第1层，41节点比51节点小，继续向后，61节点比51节点大，所以从41向下

   在第0层，51节点为要查找的节点，节点被找到，共查找4次。

   从此可以看出跳跃表比有序链表效率要高



### 3.7.Redis常用方法

| 方法名                                          | 说明                                                    |
| ----------------------------------------------- | ------------------------------------------------------- |
| 创建 jedis对象                                  | Jedis jedis = new Jedis(String ip, String port);        |
| **键操作：**                                    |                                                         |
| 清空数据                                        | jedis.flushDB()                                         |
| 判断某个键是否存在                              | boolean jedis.exists(String key)                        |
| 新增键值对(key,value)                           | jedis.set(String key,String value)                      |
| 获取所有key                                     | Set<String> jedis.keys("*")                             |
| 删除键为key的数据项                             | jedis.del(String key)                                   |
| 设置键为key的过期时间为i秒                      | jedis.expire(String key,int i)                          |
| 获取键为key数据项的剩余生存时间(秒)             | int jedis.ttl(String key)                               |
| 移除键为key属性项的生存时间限制                 | jedis.persist(String key)                               |
| 查看键为key所对应value的数据类型                | jedis.type(String key)                                  |
| **字符串操作：**                                |                                                         |
| 增加（或覆盖）数据项                            | jedis.set(String key,String value)                      |
| 不覆盖增加数据项（重复不插入）                  | jedis.setnx(String key,String value)                    |
| 增加数据项并设置有效时间                        | jedis.setex(String key,int t,String value)              |
| 删除键为key的数据项                             | jedis.del(String key)                                   |
| 获取键为key对应的value                          | jedis.get(String key)                                   |
| 在key对应value后面扩展字符串s                   | jedis.append(String key,String s)                       |
| 增加多个键值对                                  | jedis.mset(String k1,String v1,String k2,String v2,...) |
| 获取多个key对应的value                          | String [] jedis.mget(String k1,String k2,...)           |
| 删除多个key对应的数据项                         | jedis.del(new String []{String k1,String k2,...})       |
| 获取key对应的value并更新value                   | String jedis.getSet(String key,String value)            |
| 获取key对应value第i到j字符                      | String jedis.getrange(String key,int i,int j)           |
| **整数和浮点数操作：**                          |                                                         |
| 增加（或覆盖）数据项                            | jedis.set(String key,String value)                      |
| 获取键为key对应的value                          | jedis.get(String key)                                   |
| 将key对应的value自加1                           | jedis.incr(String key)                                  |
| 将key对应的value自加n                           | jedis.incrBy(String key,int n)                          |
| 将key对应的value自减1                           | jedis.decr(String key)                                  |
| 将key对应的value自减n                           | jedis.decrBy(String key,int n)                          |
| **列表（List）操作：**                          |                                                         |
| 增加一个List                                    | jedis.lpush(String key,String v1,String v2,...)         |
| 往key对应List左插入一个元素Vn                   | jedis.lpush(String key,String Vn)                       |
| 获取key对应List区间[i,j]的元素                  | jedis.lrange(String key,int i,int j)                    |
| 删除指定元素val个数num                          | jedis.lrem(String key,int num,String val)               |
| 删除List区间[i,j]之外的元素                     | jedis.ltrim(String key,int i,int j)                     |
| key对应List左出栈一个元素                       | jedis.lpop(String key)                                  |
| key对应List右插入一个元素Vn                     | jedis.rpush(String key,String Vn)                       |
| key对应List右出栈一个元素                       | jedis.rpop(String key)                                  |
| 修改key对应List指定下标index的元素              | jedis.lset(String key,int index,String val)             |
| 获取key对应List的长度                           | jedis.llen(String key)                                  |
| 获取key对应List小标为index的元素                | jedis.lindex(String key,int index)                      |
| 把key对应List里面的元素从小到大排序             | jedis.sort(String key)                                  |
| **列表（Set）操作：**                           |                                                         |
| 添加一个Set                                     | jedis.sadd(String key,String v1,String v2,...)          |
| 获取key对应set的所有元素                        | jedis.smembers(String key)                              |
| 删除一个值为val的元素                           | jedis.srem(String key,String val)                       |
| 删除值为v1，v2，...的元素                       | jedis.srem(String key, Sting v1, String v2,…)           |
| 随机弹出栈set里的一个元素                       | jedis.spop(String key)                                  |
| 获取set元素个数                                 | jedis.scared(String key)                                |
| 将元素val从集合key1中移到key2中                 | jedis.smove(String key1, String key2, String val)       |
| 获取集合key1和集合key2的交集                    | jedis.sinter(String key1, String key2)                  |
| 获取集合key1和集合key2的并集                    | jedis.sunion(String key1, String key2)                  |
| 获取集合key1和集合key2的差集                    | jedis.sdiff(String key1,String key2)                    |
| **哈希（Hash）操作：**                          |                                                         |
| 添加一个Hash                                    | jedis.hmset(String key,Map map)                         |
| 向Hash中插入一个元素（K-V）                     | jedis.hset(String key,String key, String value)         |
| 获取Hash的所有（K-V） 元素                      | jedis.hgetAll(String key)                               |
| 获取Hash所有元素的key                           | jedis.hkeys（String key）                               |
| 获取Hash所有元素 的value                        | jedis.hvals(String key)                                 |
| 把Hash中对应的k元素的值 val+=i                  | jedis.hincrBy(String key , String k, int i)             |
| 把Hash中对应的k元素的值 val-=i                  | jedis.hdecrBy(String key,String k, int i)               |
| 从Hash中删除一个或多个元素                      | jedis.hdel(String key , String k1, String k2,…)         |
| 获取Hash中元素的个数                            | jedis.hlen(String key)                                  |
| 判断Hash中是否存在K1对应的元素                  | jedis.hexists(String key,String K1)                     |
| 获取Hash中一个或多个元素value                   | jedis.hmget(String key,String K1,String K2)             |
| **有序集合（Zsort）操作：**                     |                                                         |
| 添加一个ZSet                                    | jedis.zadd(String key,Map map)                          |
| 往 ZSet插入一个元素（Score-Val）                | jedis.hset(String key,int score , int val)              |
| 获取ZSet 里下表[i,j] 区间元素Val                | jedis.zrange(String key, int i , int j)                 |
| 获取ZSet 里下表[i,j] 区间元素Score - Val        | jedis. zrangeWithScore(String key,int i , int j)        |
| 获取ZSet里score[i,j]分数区间的元素（Score-Val） | jedis.zrangeByScore(String , int i , int j)             |
| 获取ZSet里value元素的Score                      | jeids.zscore(String key,String value)                   |
| 获取ZSet里value元素的score的排名                | jedis.zrank(String key,String value)                    |
| 删除ZSet里的value元素                           | jedis.zrem(String key,String value)                     |
| 获取ZSet的元素个数                              | jedis.zcard(String key)                                 |
| 获取ZSet总score在[i,j]区间的元素个数            | jedis.zcount(String key , int i ,int j)                 |
| 把ZSet中value元素的score+=n                     | jedis.zincrby(String key,int n , String value)          |
| **排序操作：**                                  |                                                         |
| 使用排序， 首先需要生成一个排序对象             | SortingParams  sortingParams =  new SortingParams();    |
| 队列按首字母a-z 排序                            | jedis.sort(String key,sortingParams.alpha())            |
| 队列按数字升序排列                              | jedis.sort(String key, sortingParams.asc() )            |
| 队列按数字降序排列                              | jedis.sort(String key , sortingParams.desc())           |



## 4.Redis配置文件介绍

**配置文件redis.conf**

### 4.1.Units单位

配置大小单位,开头定义了一些基本的度量单位，只支持bytes，不支持bit，大小写不敏感

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215083713.png)



### 4.2.INCLUDES

类似jsp中的include，多实例的情况可以把公用的配置文件提取出来

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215083915.png)



### 4.3.网络相关配置

#### 4.3.1.bind

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215104517.png)

默认情况bind=127.0.0.1只能接受本机的访问请求

不写的情况下，无限制接受任何ip地址的访问

生产环境肯定要写你应用服务器的地址；服务器是需要远程访问的，所以需要将其注释掉

**如果开启了protected-mode，那么在没有设定bind ip且没有设密码的情况下，Redis只允许接受本机的响应**



#### 4.3.2.protected-mode

**将本机访问保护模式设置no**



#### 4.3.3.tcp-backlog

设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。

在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。

注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值（128），所以需要确认增大/proc/sys/net/core/somaxconn和/proc/sys/net/ipv4/tcp_max_syn_backlog（128）两个值来达到想要的效果

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215104809.png)



#### 4.3.4.timeout

一个空闲的客户端维持多少秒会关闭，0表示关闭该功能。即永不关闭。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215105035.png)



#### 4.3.5.tcp-keepalive

对访问客户端的一种心跳检测，每个n秒检测一次。

单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60 

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215105144.png)



### 4.4.GENERAL通用

#### 4.4.1.daemonize

是否为后台进程，设置为yes，守护进程，后台启动

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215105343.png)



#### 4.4.2.pidfile

存放pid文件的位置，每个实例会产生一个不同的pid文件

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215105443.png)



#### 4.4.3.loglevel

指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为**notice**

**四个级别根据使用阶段来选择，生产环境选择notice 或者warning**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215105607.png)



#### 4.4.4.logfile 

日志文件名称

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215105720.png)



#### 4.4.5.databases 16 

设定库的数量 默认16，默认数据库为0，可以使用SELECT <dbid>命令在连接上指定数据库id

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215105814.png)



### 4.5.SECURITY安全

#### 4.5.1.设置密码

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215110440.png)

访问密码的查看、设置和取消

在命令中设置密码，只是临时的。重启redis服务器，密码就还原了。

永久设置，需要在配置文件中进行设置。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215110511.png)



### 4.6.LIMITS限制

#### 4.6.1.maxclients

- 设置redis同时可以与多少个客户端进行连接。

- 默认情况下为10000个客户端。

- 如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。

  ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215110754.png)



#### 4.6.2.maxmemory

- 建议**必须设置**，否则，将内存占满，造成服务器宕机

- 设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定

- 如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。

- 但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。

  ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215111029.png)



#### 4.6.3.maxmemory-policy

- volatile-lru：使用LRU算法移除key，只对设置了过期时间的键；（最近最少使用）

- allkeys-lru：在所有集合key中，使用LRU算法移除key

- volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键

- allkeys-random：在所有集合key中，移除随机的key

- volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key

- noeviction：不进行移除。针对写操作，只是返回错误信息

  ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215111422.png)



#### 4.6.4.maxmemory-samples

- 设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU的那个。

- 一般设置3到7的数字，数值越小样本越不准确，但性能消耗越小。

  ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215111537.png)



## 5.Redis的发布和订阅

### 5.1.什么是发布和订阅

Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。

Redis 客户端可以订阅任意数量的频道。



#### 5.2.Redis的发布和订阅

1. 客户端可以订阅频道如下图

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151320.png)

2. 当给这个频道发布消息后，消息就会发送给订阅的客户端

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/2022021501320.png)



#### 5.3.发布订阅命令行实现

1. 打开一个客户端订阅channel2，命令`SUBSCRIBE channel2`
2. 打开另一个客户端，使用命令`publish channel2 hello1`给频道channel2发布消息hello1
3. 返回的(integer)1是订阅者数量

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215133726.png)

**注：**发布的消息没有持久化，如果在订阅的客户端收不到hello，只能收到订阅后发布的消息



## 6.Redis新数据类型

### 6.1.Bitmaps

#### 6.1.1.简介

现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 例如“abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、 01100010和01100011，如下图

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151341.png)

合理地使用操作位能够有效地提高内存使用率和开发效率。

Redis提供了Bitmaps这个“数据类型”可以实现对位的操作：

- （1） Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。
- （1） Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151345.png)



#### 6.1.2.命令

1. **setbit**

   **格式:**setbit<key><offset><value>设置Bitmaps中某个偏移量的值（0或1）

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151352.png)

   **offset:**偏移量从0开始

   **实例:**每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id。

   设置键的第offset个位的值（从0算起） ， 假设现在有20个用户，userid=1， 6， 11， 15， 19的用户对网站进行了访问， 那么当前Bitmaps初始化结果如图

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151353.png)unique:users:20201106代表2020-11-06这天的独立访问用户的Bitmaps![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151354.png)**注：**

   很多应用的用户id以一个指定数字（例如10000) 开头， 直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费， 通常的做法是每次做setbit操作时将用户id减去这个指定数字。

   在第一次初始化Bitmaps时， 假如偏移量非常大， 那么整个初始化过程执行会比较慢， 可能会造成Redis的阻塞。

2. **getbit**

   **格式：**getbit<key><offset>获取Bitmaps中某个偏移量的值

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151356.png)获取键的第offset位的值（从0开始算)

   **实例：**

   获取id=8的用户是否在2020-11-06这天访问过， 返回0说明没有访问过：![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151400.png)

   注：因为100根本不存在，所以也是返回0

3. **bitcount**

   统计**字符串**被设置为1的bit数。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，start、end 是指bit组的字节的下标数，二者皆包含。

   **格式:**

   bitcount<key>[start end] 统计字符串从start字节到end字节比特值为1的数量![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151402.png)

   **实例:**

   计算2022-11-06这天的独立访问用户数量![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151403.png)

   start和end代表起始和结束字节数， 下面操作计算用户id在第1个字节到第3个字节之间的独立访问用户数， 对应的用户id是11， 15， 19。![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151404.png)

    K1 【01000001 01000000  00000000 00100001】，对应【0，1，2，3】

   bitcount K1 1 2  ： 统计下标1、2字节组中bit=1的个数，即01000000  00000000

   --》bitcount K1 1 2 　　--》1

   bitcount K1 1 3  ： 统计下标1、2字节组中bit=1的个数，即01000000  00000000 00100001

   --》bitcount K1 1 3　　--》3

   bitcount K1 0 -2  ： 统计下标0到下标倒数第2，字节组中bit=1的个数，即01000001  01000000  00000000

   --》bitcount K1 0 -2　　--》3

    **注意：**redis的setbit设置或清除的是bit位置，而bitcount计算的是byte位置。

4. **bitop**

   **格式:**

   bitop and(or/not/xor) <destkey> [key…]![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151406.png)

   bitop是一个复合操作， 它可以做多个Bitmaps的and（交集） 、 or（并集） 、 not（非） 、 xor（异或） 操作并将结果保存在destkey中。

   **实例:**

   ```
   2020-11-04 日访问网站的userid=1,2,5,9。
   setbit unique:users:20201104 1 1
   setbit unique:users:20201104 2 1
   setbit unique:users:20201104 5 1
   setbit unique:users:20201104 9 1
   
   2020-11-03 日访问网站的userid=0,1,4,9。
   setbit unique:users:20201103 0 1
   setbit unique:users:20201103 1 1
   setbit unique:users:20201103 4 1
   setbit unique:users:20201103 9 1
   
   计算出两天都访问过网站的用户数量
   bitop and unique:users:and:20201104_03 unique:users:20201103 unique:users:20201104
   ```

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151409.png)

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151410.png)

计算出任意一天都访问过网站的用户数量（例如月活跃就是类似这种） ， 可以使用or求并集

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151411.png)



#### 6.1.3.Bitmaps与set对比

假设网站有1亿用户， 每天独立访问的用户有5千万， 如果每天用集合类型和Bitmaps分别存储活跃用户可以得到表

| set和Bitmaps存储一天活跃用户对比 |                    |                  |                        |
| -------------------------------- | ------------------ | ---------------- | ---------------------- |
| 数据类型                         | 每个用户id占用空间 | 需要存储的用户量 | 全部内存量             |
| 集合类型                         | 64位               | 50000000         | 64位*50000000 = 400MB  |
| Bitmaps                          | 1位                | 100000000        | 1位*100000000 = 12.5MB |

很明显， 这种情况下使用Bitmaps能节省很多的内存空间， 尤其是随着时间推移节省的内存还是非常可观的

| set和Bitmaps存储独立用户空间对比 |        |        |       |
| -------------------------------- | ------ | ------ | ----- |
| 数据类型                         | 一天   | 一个月 | 一年  |
| 集合类型                         | 400MB  | 12GB   | 144GB |
| Bitmaps                          | 12.5MB | 375MB  | 4.5GB |

但Bitmaps并不是万金油， 假如该网站每天的独立访问用户很少， 例如只有10万（大量的僵尸用户） ， 那么两者的对比如下表所示， 很显然， 这时候使用Bitmaps就不太合适了， 因为基本上大部分位都是0。

| set和Bitmaps存储一天活跃用户对比（独立用户比较少） |                    |                  |                        |
| -------------------------------------------------- | ------------------ | ---------------- | ---------------------- |
| 数据类型                                           | 每个userid占用空间 | 需要存储的用户量 | 全部内存量             |
| 集合类型                                           | 64位               | 100000           | 64位*100000 = 800KB    |
| Bitmaps                                            | 1位                | 100000000        | 1位*100000000 = 12.5MB |



### 6.2.HyperLogLog

#### 6.2.1.简介

在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站PV（PageView页面访问量）,可以使用Redis的incr、incrby轻松实现。

但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？这种求集合中不重复元素个数的问题称为基数问题。

解决基数问题有很多种方案：

1. 数据存储在MySQL表中，使用distinct count计算不重复个数
2. 使用Redis提供的hash、set、bitmaps等数据结构来处理

以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的。

能否能够降低一定的精度来平衡存储空间？Redis推出了HyperLogLog

Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。

在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。

但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

什么是基数?

比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)有5个就为5。 基数估计就是在误差可接受的范围内，快速计算基数。



#### 6.2.2.命令

1. **pfadd**

   **格式：**

   pfadd <key>< element> [element ...]  添加指定元素到 HyperLogLog 中![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151442.png)

   **实例：**![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151443.png)

   将所有元素添加到指定HyperLogLog数据结构中。如果执行命令后HLL估计的近似基数发生变化，则返回1，否则返回0。

2. **pfcount**

   **格式：**

   pfcount<key> [key ...] 计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151444.png)

   **实例：**![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151245.png)

   ```
   127.0.0.1:6379> pfadd program "java"
   (integer) 1
   127.0.0.1:6379> pfcount program
   (integer) 1
   127.0.0.1:6379> pfadd program "c++"
   (integer) 1
   127.0.0.1:6379> pfcount program
   (integer) 2
   127.0.0.1:6379> pfadd program "java"
   (integer) 0
   127.0.0.1:6379> pfcount program
   (integer) 2
   再次添加已存在的"java"时，统计的还是2
   ```

   

3. **pfmerge**

   **格式：**

   pfmerge<destkey><sourcekey> [sourcekey ...] 将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151446.png)

   **实例：**![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151447.png)![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215150647.png)

将v1和v2的值统计到v3中，v1的值还是存在的。



### 6.3.Geospatial

#### 6.3.1.简介

Redis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。



#### 6.3.2.命令

1. **geoadd**

   **格式：**

   geoadd<key>< longitude><latitude><member> [longitude latitude member...] 添加地理位置（经度，纬度，名称）![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151511.png)

   **实例：**

   ```
   geoadd china:city 121.47 31.23 shanghai
   geoadd china:city 106.50 29.53 chongqing 114.05 22.52 shenzhen 116.38 39.90 beijing
   ```

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151512.png)

   两极无法直接添加，一般会下载城市数据，直接通过 Java 程序一次性导入。

   有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度。

   当坐标位置超出指定范围时，该命令将会返回一个错误。

   已经添加的数据，是无法再次往里面添加的。

2. **geopos**

   **格式：**

   geopos  <key><member> [member...]  获得指定地区的坐标值![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151514.png)

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215152503.png)

3. **geodist**

   **格式：**

   geodist<key><member1><member2>  [m|km|ft|mi ]  获取两个位置之间的直线距离

   **实例：**

   获取两个位置之间的直线距离：![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151517.png)单位：

   **m：** 表示单位为米[默认值]。

   **km：** 表示单位为千米。

   **mi：** 表示单位为英里。

   **ft：** 表示单位为英尺。

   如果用户没有显式地指定单位参数， 那么 GEODIST 默认使用米作为单位

4. **georadius**

   **格式：**

   georadius<key>< longitude><latitude>radius m|km|ft|mi  以给定的经纬度为中心，找出某一半径内的元素![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151519.png)经度 纬度 距离 单位

   **实例：**![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202151520.png)



## 7.Redis_Jedis_测试

### 7.1.创建工程

新建一个maven工程

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215153655.png)

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215153851.png)



### 7.2.引入Jar包

```xml
<dependency>
<groupId>redis.clients</groupId>
<artifactId>jedis</artifactId>
<version>3.2.0</version>
</dependency>
```



### 7.3.测试连接Redis

创建JedisDemo1类

```java
package com.ama.jedis;

import redis.clients.jedis.Jedis;

/**
 * Jedis测试
 *
 * @Version 0.0.1
 * @Author WenZhe Wang
 * @Date 2022/2/15 15:43
 */
public class JedisDemo1 {

    public static void main(String[] args) {
        //创建Jedis对象
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.218.131", 6379);

        //测试
        String value = jedis.ping();
        System.out.println(value);
    }
}
```

运行main方法，出现超时错误

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215155216.png)

检查redis.conf配置文件，注释掉：bind 127.0.0.1，然后protected-mode no，

检查防火墙状态；命令`systemctl status firewalld`

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215155337.png)

关闭防火墙；命令`systemctl stop firewalld`

不关闭防火墙可以将6379端口号进行放行`firewall-cmd --zone=public --add-port=6379``/tcp` `--permanent`，再重启防火墙`systemctl restart firewalld.service`

重新运行main方法，连接redis成功，返回PONG

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220215160154.png)



**Linux防火墙指令：**

**查看防火墙状态：**`firewall-cmd --state`

 running代表防火墙正在运行中,如果防火墙处在关闭状态,则运行下面命令开启防火墙

**查看某个端口是否放行：**`firewall-cmd --query-port=6379/tcp`

**放行指定端口：**`firewall-cmd --zone=public --add-port=6379/tcp --permanent`

**重启防火墙：**`systemctl restart firewalld.service`

**重新载入配置：**`firewall-cmd --reload`



### 7.4.测试相关数据类型

```java
package com.ama.jedis;

import org.junit.Test;
import redis.clients.jedis.Jedis;

import java.util.List;
import java.util.Set;

/**
 * Jedis测试
 *
 * @Version 0.0.1
 * @Author WenZhe Wang
 * @Date 2022/2/15 15:43
 */
public class JedisDemo1 {

    public static void main(String[] args) {
        //创建Jedis对象
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.218.131", 6379);

        //测试
        String value = jedis.ping();
        System.out.println(value);
    }

    /**
     * 操作Key String字符串
     */
    @Test
    public void demo1() {

        //创建Jedis对象
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.218.131", 6379);

        //添加
        jedis.set("name", "lucy");
        //获取
        String name = jedis.get("name");
        System.out.println("name===" + name);

        //添加多个key-value
        jedis.mset("k1", "v1", "k2", "v2");
        //获取多个key-value
        List<String> mget = jedis.mget("k1", "k2");
        //遍历输出
        mget.stream().forEach(System.out::println);


        Set<String> keys = jedis.keys("*");
        //遍历输出所有key
        keys.stream().forEach(System.out::println);
    }

    /**
     * 操作List集合
     */
    @Test
    public void demo2() {

        //创建Jedis对象
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.218.131", 6379);

        //添加数据
        jedis.lpush("key1", "lucy", "mary", "jack");
        //从左到右获取key1的所有value值
        List<String> valuesL = jedis.lrange("key1", 0, -1);
        //遍历输出
        valuesL.stream().forEach(System.out::println);
    }

    /**
     * 操作Set集合
     */
    @Test
    public void demo3() {

        //创建Jedis对象
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.218.131", 6379);

        //添加数据
        jedis.sadd("names", "lucy", "mary");
        //获取数据
        Set<String> names = jedis.smembers("names");
        //遍历输出
        names.stream().forEach(System.out::println);
    }

    /**
     * 操作hash
     */
    @Test
    public void demo4() {

        //创建Jedis对象
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.218.131", 6379);

        //添加数据
        jedis.hset("users", "age", "20");
        //获取数据
        String hget = jedis.hget("users", "age");
        //输出
        System.out.println("hget====" + hget);
    }

    /**
     * 操作zset
     */
    @Test
    public void demo5() {

        //创建Jedis对象
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.218.131", 6379);

        //添加数据
        jedis.zadd("china1", 100d, "shanghai");
        //获取数据(0,-1:代表获取所有值)
        Set<String> china = jedis.zrange("china1", 0, -1);
        china.stream().forEach(System.out::println);
    }
}
```



## 8.Redis_Jedis_实例

### 8.1.完成一个手机验证码功能

**需求：**

1. 输入手机号，点击发送后随机生成6位数字码，2分钟有效
2. 输入验证码，点击验证，返回成功或失败
3. 每个手机号每天只能输入3次

**代码实例：**

```java
package com.ama.jedis;

import redis.clients.jedis.Jedis;

import java.util.Random;

/**
 * @program: com.ama
 * @description: 手机验证码
 * @author: Wang WenZhe
 * @create: 2022-02-15 19:34
 **/
public class PhoneCode {
    public static void main(String[] args) {
        //模拟验证码发送
        //verifyCode("1359089898");

        //检验验证码
        getRedisCode("1359089898", "515062");
    }

    /**
     * 生成6位数字验证码
     *
     * @return 6位数字验证码
     */
    public static String getCode() {
        Random random = new Random();
        String code = "";
        for (int i = 0; i < 6; i++) {
            int rand = random.nextInt(10);
            code += rand;
        }
        return code;
    }

    /**
     * 每个手机每天只能发送三次，验证码放到redis中，设置过期时间
     *
     * @param phone 手机号
     */
    public static void verifyCode(String phone) {
        //连接redis
        //host:虚拟机iP地址
        Jedis jedis = new Jedis("192.168.234.128", 6379);

        //拼接key
        //手机发送次数key
        String countKey = "VerifyCode" + phone + "count";

        //验证码key
        String codeKey = "VerifyCode" + phone + "code";

        //根据Key获取value
        String count = jedis.get(countKey);
        if (count == null) {
            //没有发送次数，第一次发送
            //设置value发送次数是1
            jedis.setex(countKey, 24 * 60 * 60, "1");
        } else if (Integer.parseInt(count) <= 2) {
            //发送次数+1
            //对countKey键的value值进行+1;
            jedis.incr(countKey);
        } else if (Integer.parseInt(count) > 2) {
            //发送三次，不能再发送
            System.out.println("今天发送次数已经超过三次");
            jedis.close();
            return;
        }

        //获取验证码
        String vCode = getCode();
        //发送验证码放到redis里面，设置过期时间2分钟
        jedis.setex(codeKey, 120, vCode);
    }

    /**
     * 验证码校验
     *
     * @param phone 手机号
     * @param code  验证码
     */
    public static void getRedisCode(String phone, String code) {
        //连接redis
        Jedis jedis = new Jedis("192.168.234.128", 6379);
        //验证码key
        String codeKey = "VerifyCode" + phone + "code";
        //从redis获取验证码
        String redisCode = jedis.get(codeKey);
        if (redisCode == null) {
            System.out.println("验证码已过期");
            return;
        }
        //判断
        if (redisCode.equals(code)) {
            System.out.println("成功");
        } else {
            System.out.println("失败");
        }
        jedis.close();
    }

}

```



## 9.Redis与Spring Boot整合

### 9.1.整合步骤

#### 9.1.1.创建Spring Boot项目

1. 创建一个名叫**redis_shpringboot**项目。![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216092730.png)![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216092950.png)

2. **引入依赖**

   ```xml
   <?xml version="1.0" encoding="UTF-8"?>
   <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
            xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
       <modelVersion>4.0.0</modelVersion>
       <parent>
           <groupId>org.springframework.boot</groupId>
           <artifactId>spring-boot-starter-parent</artifactId>
           <version>2.2.1.RELEASE</version>
           <relativePath/> <!-- lookup parent from repository -->
       </parent>
       <groupId>com.ama</groupId>
       <artifactId>redis_springboot</artifactId>
       <version>0.0.1-SNAPSHOT</version>
       <name>redis_springboot</name>
       <description>Demo project for Spring Boot</description>
       <properties>
           <java.version>1.8</java.version>
       </properties>
       <dependencies>
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-web</artifactId>
           </dependency>
   
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-test</artifactId>
               <scope>test</scope>
           </dependency>
   
           <!-- redis -->
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-data-redis</artifactId>
           </dependency>
   
           <!-- spring2.X集成redis所需common-pool2-->
           <dependency>
               <groupId>org.apache.commons</groupId>
               <artifactId>commons-pool2</artifactId>
               <version>2.6.0</version>
           </dependency>
   
       </dependencies>
   
       <build>
           <plugins>
               <plugin>
                   <groupId>org.springframework.boot</groupId>
                   <artifactId>spring-boot-maven-plugin</artifactId>
               </plugin>
           </plugins>
       </build>
   
   </project>
   ```

3. **application.properties配置redis配置**

   ```properties
   #Redis服务器地址
   spring.redis.host=192.168.218.131
   #Redis服务器连接端口
   spring.redis.port=6379
   #Redis数据库索引（默认为0）
   spring.redis.database= 0
   #连接超时时间（毫秒）
   spring.redis.timeout=1800000
   #连接池最大连接数（使用负值表示没有限制）
   spring.redis.lettuce.pool.max-active=20
   #最大阻塞等待时间(负数表示没限制)
   spring.redis.lettuce.pool.max-wait=-1
   #连接池中的最大空闲连接
   spring.redis.lettuce.pool.max-idle=5
   #连接池中的最小空闲连接
   spring.redis.lettuce.pool.min-idle=0
   ```

4. **添加redis配置类**

   ```java
   package com.ama.redis_springboot.config;
   
   import com.fasterxml.jackson.annotation.JsonAutoDetect;
   import com.fasterxml.jackson.annotation.PropertyAccessor;
   import com.fasterxml.jackson.databind.ObjectMapper;
   import org.springframework.cache.CacheManager;
   import org.springframework.cache.annotation.CachingConfigurerSupport;
   import org.springframework.cache.annotation.EnableCaching;
   import org.springframework.context.annotation.Bean;
   import org.springframework.context.annotation.Configuration;
   import org.springframework.data.redis.cache.RedisCacheConfiguration;
   import org.springframework.data.redis.cache.RedisCacheManager;
   import org.springframework.data.redis.connection.RedisConnectionFactory;
   import org.springframework.data.redis.core.RedisTemplate;
   import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
   import org.springframework.data.redis.serializer.RedisSerializationContext;
   import org.springframework.data.redis.serializer.RedisSerializer;
   import org.springframework.data.redis.serializer.StringRedisSerializer;
   
   import java.time.Duration;
   
   /**
    * Redis配置类
    *
    * @Version 0.0.1
    * @Author WenZhe Wang
    * @Date 2022/2/16 10:40
    */
   
   /**
    * @EnableCaching 开启缓存
    */
   @EnableCaching
   @Configuration
   public class RedisConfig extends CachingConfigurerSupport {
   
       @Bean
       public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
           RedisTemplate<String, Object> template = new RedisTemplate<>();
           RedisSerializer<String> redisSerializer = new StringRedisSerializer();
           Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
           ObjectMapper om = new ObjectMapper();
           om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
           om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
           jackson2JsonRedisSerializer.setObjectMapper(om);
           template.setConnectionFactory(factory);
           //key序列化方式
           template.setKeySerializer(redisSerializer);
           //value序列化
           template.setValueSerializer(jackson2JsonRedisSerializer);
           //value hashmap序列化
           template.setHashValueSerializer(jackson2JsonRedisSerializer);
           return template;
       }
   
       @Bean
       public CacheManager cacheManager(RedisConnectionFactory factory) {
           RedisSerializer<String> redisSerializer = new StringRedisSerializer();
           Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
           //解决查询缓存转换异常的问题
           ObjectMapper om = new ObjectMapper();
           om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
           om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
           jackson2JsonRedisSerializer.setObjectMapper(om);
           // 配置序列化（解决乱码的问题）,过期时间600秒
           RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
                   .entryTtl(Duration.ofSeconds(600))
                   .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer))
                   .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))
                   .disableCachingNullValues();
           RedisCacheManager cacheManager = RedisCacheManager.builder(factory)
                   .cacheDefaults(config)
                   .build();
           return cacheManager;
       }
   }
   ```

5. **创建redis测试类**

   ```java
   package com.ama.redis_springboot.controller;
   
   import org.springframework.beans.factory.annotation.Autowired;
   import org.springframework.data.redis.core.RedisTemplate;
   import org.springframework.web.bind.annotation.GetMapping;
   import org.springframework.web.bind.annotation.RequestMapping;
   import org.springframework.web.bind.annotation.RestController;
   
   /**
    * RedisController测试类
    *
    * @Version 0.0.1
    * @Author WenZhe Wang
    * @Date 2022/2/16 10:59
    */
   @RestController
   @RequestMapping(value = "/redisTest")
   public class RedisTestController {
   
       @Autowired
       private RedisTemplate redisTemplate;
   
       @GetMapping(value = "/redis")
       public String testRedis() {
           //设置值到redis
           redisTemplate.opsForValue().set("name", "lucy");
           //从redis中获取值
           String name = (String) redisTemplate.opsForValue().get("name");
   
           return name;
       }
   }
   ```

6. 打开浏览器，页面成功返回name值”lucy“

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216111018.png)



## 10.Redis事务锁机制_秒杀

### 10.1.Redis的事务定义

Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

Redis事务的主要作用就是**串联多个命令**防止别的命令插队。



### 10.2.Multi、Exec、discard

从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。

组队的过程中可以通过discard来放弃组队。  

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202161126.png)



**组队成功，执行成功效果：**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216151708.png)

当执行exec执行后，表示事务结束了。

**放弃组队，命令最终不执行效果：**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216152329.png)

**组队成功，提交有成功有失败效果：**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216154432.png)



### 10.3.事务的错误处理

第一种：组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202161534.png)

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216153352.png)



第二种：如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202161536.png)

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216154432.png)



### 10.4.事务冲突的问题

#### 10.4.1.例子

一个请求想给金额减8000

一个请求想给金额减5000

一个请求想给金额减1000

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202161553.png)



#### 10.4.2.悲观锁

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202161554.png)

**悲观锁(Pessimistic Lock)**, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。**传统的关系型数据库里边就用到了很多这种锁机制**，比如**行锁**，**表锁**等，**读锁**，**写锁**等，都是在做操作之前先上锁。

**使用悲观锁的流程：**

给10000块钱先上锁，上锁之后，别人就不能操作了，只能把锁打开之后，别人才能操作，否则只能看到拿到锁的操作。比如先减了8000(在操作时，别人不能操作，有一个block，阻塞状态)，剩下2000。变成2000后，就会释放锁，别人拿到锁后，就会得到这2000，然后拿着2000再去操作。首先拿到2000后，进行上锁。2000不能减5000，所以不能操作。

悲观锁整体流程是先上锁，再操作，操作之后再解锁。

#### 10.4.3.乐观锁

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202161555.png)

**乐观锁(Optimistic Lock)**,顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。**乐观锁适用于多读的应用类型，这样可以提高吞吐量**。Redis就是利用这种**check-and-set**机制实现事务的。



#### 10.4.4.WATCH key [key ...]

在执行multi之前，先执行watch key1 [key2],可以监视一个(或多个) key ，如果在事务**执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。**

**乐观锁在redis中的使用：**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220216205532.png)



#### 10.4.5.unwatch

取消 WATCH 命令对所有 key 的监视。

如果在执行 WATCH 命令之后，EXEC 命令或DISCARD 命令先被执行了的话，那么就不需要再执行UNWATCH 了。

http://doc.redisfans.com/transaction/exec.html



### 10.5.Redis事务三特性

- 单独的隔离操作 

  事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 

- 没有隔离级别的概念 

  队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行

- 不保证原子性

  事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 



## 11.Redis事务秒杀案例

### 11.1.解决计数器和人员记录的事务操作

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202162101.png)



### 11.2.Redis事务--秒杀并发模拟

IDEA导入项目Seckill

#### 11.2.1.第一版：简单案例

目的：先在页面中实现扣减商品库存，并存储用户信息

**SecKill_redis类代码实例：**

```java
package com.atguigu;

import java.io.IOException;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import org.apache.commons.pool2.impl.GenericObjectPoolConfig;
import org.slf4j.LoggerFactory;

import ch.qos.logback.core.rolling.helper.IntegerTokenConverter;
import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisCluster;
import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;
import redis.clients.jedis.ShardedJedisPool;
import redis.clients.jedis.Transaction;

/**
 *
 */
public class SecKill_redis {

    public static void main(String[] args) {
        Jedis jedis = new Jedis("192.168.218.131", 6379);
        System.out.println(jedis.ping());
        jedis.close();
    }

    /**
     * 秒杀过程
     *
     * @param uid    用户id
     * @param prodid 商品id
     * @return 秒杀结果
     * @throws IOException
     */
    public static boolean doSecKill(String uid, String prodid) throws IOException {
        //1 uid和prodid非空判断
        if (uid == null || prodid == null) {
            return false;
        }

        //2 连接redis
        Jedis jedis = new Jedis("192.168.218.131",6379);

        //3 拼接key
        // 3.1 库存key
        String kcKey = "sk:" + prodid + ":qt";
        // 3.2 秒杀成功用户key
        String userKey = "sk:" + prodid + ":user";

        //监视库存
        jedis.watch(kcKey);

        //4 获取库存，如果库存null，秒杀还没有开始
        String kc = jedis.get(kcKey);
        if (kc == null) {
            System.out.println("秒杀还没有开始，请等待");
            jedis.close();
            return false;
        }

        // 5 判断用户是否重复秒杀操作;
        // sismember():判断集合<key>是否为含有该<value>值，有1，没有0
        if (jedis.sismember(userKey, uid)) {
            System.out.println("已经秒杀成功了，不能重复秒杀");
            jedis.close();
            return false;
        }

        //6 判断如果商品数量，库存数量小于1，秒杀结束
        if (Integer.parseInt(kc) <= 0) {
            System.out.println("秒杀已经结束了");
            jedis.close();
            return false;
        }
        //7.1 库存-1
        jedis.decr(kcKey);
        //7.2 把秒杀成功用户添加清单里面
        jedis.sadd(userKey, uid);

        System.out.println("秒杀成功了..");
        jedis.close();
        return true;
    }
}

```

**SecKillServlet类代码实例:**

```java
package com.atguigu;

import java.io.IOException;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.Random;

import javax.servlet.ServletException;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import javax.xml.ws.soap.AddressingFeature.Responses;

/**
 * 秒杀案例
 */
public class SecKillServlet extends HttpServlet {
	private static final long serialVersionUID = 1L;

    public SecKillServlet() {
        super();
    }

	protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {

		String userid = new Random().nextInt(50000) +"" ;
		String prodid =request.getParameter("prodid");
		
		boolean isSuccess=SecKill_redis.doSecKill(userid,prodid);
		//boolean isSuccess= SecKill_redisByScript.doSecKill(userid,prodid);
		response.getWriter().print(isSuccess);
	}
}
```

然后在redis中存储商品信息

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220217110037.png)

**过程解析：**

1. 代码编完之后，启动，成功访问页面。
2. 在redis中使用命令`set sk:0101:qt 10`：存放商品信息，数量为10。
3. 使用`keys *`查看商品信息是否存到redis中。
4. 点击页面中的”秒杀点我“按钮，IDEA控制台输出”秒杀成功了..“。
5. 使用命令`keys *`，查看当前的所有键值对数据，抢购的用户信息已经存入到redis中。
6. 使用命令`get sk:0101:qt`，查看商品的数量是否减1了，变成9。
7. 使用命令`smembers sk:0101:user`，查看用户信息。不能使用`get`指令，因为我们将用户信息存放到了Set集合，这样便于用户不能重复抢购。
8. 当在页面点击”秒杀点我“按钮10次时，页面提示抢光了。
9. 使用命令`get sk:0101:qt`，查看商品的数量显示为0，已抢光商品。
10. 使用命令`SMEMBERS sk:0101:user`，查看用户信息，用户的数量也刚好为10。



#### 11.2.2.第二版：多人抢购并发案例

##### 11.2.2.1.安装ab工具

使用工具ab模拟测试

CentOS6 默认安装

**CentOS7安装步骤：**

在联网情况下：使用命令`yum install httpd-tools`



##### 11.2.2.2.通过ab测试

使用`vi postfile` 模拟表单提交参数,以&符号结尾;存放当前目录。

postfile的内容：

```
prodid=0101&
```

使用指令

```java
//表示2000个请求，其中100个请求是并发，~/是指当前路径下(/root/目录下)，ip地址是自己电脑的iP地址,不是虚拟机ip地址
ab -n 2000 -c 100 -p ~/postfile -T application/x-www-form-urlencoded http://192.168.63.1:7788/Seckill/doseckill
```

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220217135007.png)

测试结果发现控制台出现了秒杀已经结束了还有秒杀成功的情况。并且商品数量从10变成了-15，出现了超卖情况。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220217134809.png)

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220217135228.png)

测试时可能会出现一个连接超时问题，因为redis肯定不能同时处理2000请求，比如2000个请求中有一个请求不能处理，就需要等待。如果等待时间过长，最终还没有连上，就会出现连接超时问题。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/.png)

**结果：**

目前的测试结果有两个问题

1. 会出现超卖问题
2. 可能会出现连接超时问题。



#### 11.2.3.第三版：超时问题和超卖问题

##### 11.2.3.1.超时问题

创建JedisPoolUtil类，代码如下：

```java
package com.atguigu;

import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;

public class JedisPoolUtil {
	private static volatile JedisPool jedisPool = null;

	private JedisPoolUtil() {
	}

	public static JedisPool getJedisPoolInstance() {
		if (null == jedisPool) {
			synchronized (JedisPoolUtil.class) {
				if (null == jedisPool) {
					JedisPoolConfig poolConfig = new JedisPoolConfig();
					poolConfig.setMaxTotal(200);
					poolConfig.setMaxIdle(32);
					poolConfig.setMaxWaitMillis(100*1000);
					poolConfig.setBlockWhenExhausted(true);
					poolConfig.setTestOnBorrow(true);  // ping  PONG
				 
					jedisPool = new JedisPool(poolConfig, "192.168.218.131", 6379, 60000 );
				}
			}
		}
		return jedisPool;
	}

	public static void release(JedisPool jedisPool, Jedis jedis) {
		if (null != jedis) {
			jedisPool.returnResource(jedis);
		}
	}

}
```

修改SecKill_redis中的doSecKill方法，将连接redis方法修改，使用JedisPool连接

```java
//2 连接redis
        //Jedis jedis = new Jedis("192.168.218.131",6379);
        //通过连接池得到jedis对象
        JedisPool jedisPoolInstance = JedisPoolUtil.getJedisPoolInstance();
        Jedis jedis = jedisPoolInstance.getResource();
```



##### 11.2.3.2.超卖问题

**利用乐观锁淘汰用户，解决超卖问题**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202171429.png)



修改SecKill_redis中的doSecKill方法

```java
package com.atguigu;

import java.io.IOException;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import org.apache.commons.pool2.impl.GenericObjectPoolConfig;
import org.slf4j.LoggerFactory;

import ch.qos.logback.core.rolling.helper.IntegerTokenConverter;
import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisCluster;
import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;
import redis.clients.jedis.ShardedJedisPool;
import redis.clients.jedis.Transaction;

/**
 *
 */
public class SecKill_redis {

    public static void main(String[] args) {
        Jedis jedis = new Jedis("192.168.218.131", 6379);
        System.out.println(jedis.ping());
        jedis.close();
    }

    /**
     * 秒杀过程
     *
     * @param uid    用户id
     * @param prodid 商品id
     * @return 秒杀结果
     * @throws IOException
     */
    public static boolean doSecKill(String uid, String prodid) throws IOException {
        //1 uid和prodid非空判断
        if (uid == null || prodid == null) {
            return false;
        }

        //2 连接redis
        //Jedis jedis = new Jedis("192.168.218.131",6379);
        //通过连接池得到jedis对象
        JedisPool jedisPoolInstance = JedisPoolUtil.getJedisPoolInstance();
        Jedis jedis = jedisPoolInstance.getResource();

        //3 拼接key
        // 3.1 库存key
        String kcKey = "sk:" + prodid + ":qt";
        // 3.2 秒杀成功用户key
        String userKey = "sk:" + prodid + ":user";

        //监视库存
        jedis.watch(kcKey);

        //4 获取库存，如果库存null，秒杀还没有开始
        String kc = jedis.get(kcKey);
        if (kc == null) {
            System.out.println("秒杀还没有开始，请等待");
            jedis.close();
            return false;
        }

        // 5 判断用户是否重复秒杀操作;
        // sismember():判断集合<key>是否为含有该<value>值，有1，没有0
        if (jedis.sismember(userKey, uid)) {
            System.out.println("已经秒杀成功了，不能重复秒杀");
            jedis.close();
            return false;
        }

        //6 判断如果商品数量，库存数量小于1，秒杀结束
        if (Integer.parseInt(kc) <= 0) {
            System.out.println("秒杀已经结束了");
            jedis.close();
            return false;
        }

        //7 秒杀过程
        //使用事务
        Transaction multi = jedis.multi();

        //组队操作
        //decr()将key对应的value自减1
        multi.decr(kcKey);
        //添加一个Set集合
        multi.sadd(userKey, uid);

        //执行
        List<Object> results = multi.exec();

        if (results == null || results.size() == 0) {
            System.out.println("秒杀失败了....");
            jedis.close();
            return false;
        }

        //7.1 库存-1
        //jedis.decr(kcKey);
        //7.2 把秒杀成功用户添加清单里面
        //jedis.sadd(userKey, uid);

        System.out.println("秒杀成功了..");
        jedis.close();
        return true;
    }
}
```

使用ab工具模拟并发抢购，命令`ab -n 2000 -c 100 -p ~/postfile -T application/x-www-form-urlencoded http://192.168.63.1:7788/Seckill/doseckill`

**测试结果:**

出现秒杀成功了和秒杀失败了。在redis中查看商品数量=0，没有出现超卖情况。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220217144536.png)



**总结：**

1. 先用**watch**监视库存
2. 然后放到事务中**multi**
3. 进行组队操作。库存数量进行减1操作，将用户信息放到Set集合中
4. 执行事务exec



#### 11.2.4.第四版：解决库存遗留问题

当使用乐观锁时可能会出现库存遗留问题。

**原因：**假如商品有500个，发送一个2000，300个并发请求`ab -n 2000 -c 300 -p ~/postfile -T application/x-www-form-urlencoded http://192.168.63.1:7788/Seckill/doseckill`。2000个人去抢购500个商品，其中有一个人购买之后需要修改版本号，剩下的1999个人对比版本号不一样，那么这1999个都不能进行其它操作。因为版本号的不同，所以剩下的499个商品无法出售。

解决方案使用**Lua**解决存库遗留问题

##### 11.2.4.1.LUA脚本

Lua 是一个小巧的脚本语言，Lua脚本可以很容易的被C/C++ 代码调用，也可以反过来调用C/C++的函数，Lua并没有提供强大的库，一个完整的Lua解释器不过200k，所以Lua不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。

很多应用程序、游戏使用LUA作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。

这其中包括魔兽争霸地图、魔兽世界、博德之门、愤怒的小鸟等众多游戏插件或外挂。

https://www.w3cschool.cn/lua/



##### 11.2.4.2.LUA脚本在Redis中的优势

将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。提升性能。

LUA脚本是类似redis事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作。

但是注意redis的lua脚本功能，只有在Redis 2.6以上的版本才可以使用。

利用lua脚本淘汰用户，解决超卖问题。

redis 2.6版本以后，通过lua脚本解决**争抢问题**，实际上是**redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题**。

**通俗说拿抢购举例：**抢购分为两步，第一步将减少库存，第二步增加用户清单，写一个Lua脚本，当脚本提交给redis，reids就会把Lua脚本直接执行，中间无法干预，只有执行完成之后别人才能干预，才可以进行操作。

**Lua脚本：**

```lua
--获取用户信息
local userid=KEYS[1]; 
--获取商品信息
local prodid=KEYS[2];
--拼接库存key
local qtkey="sk:"..prodid..":qt";
--拼接用户key
local usersKey="sk:"..prodid.":usr'; 
--redis.call是调用redis中的命令，判断目前的用户在用户清单中是否存在
local userExists=redis.call("sismember",usersKey,userid);
--如果值是1，返回2,2代表该用户已存在，不能再参与秒杀
if tonumber(userExists)==1 then 
  return 2;
end
--获取库存商品数量
local num= redis.call("get" ,qtkey);
--如果库存商品数量小于等于0，代表秒杀结束
if tonumber(num)<=0 then 
  return 0; 
--秒杀没有结束
else 
--库存减1
  redis.call("decr",qtkey);
--添加抢购到的用户信息到用户清单
  redis.call("sadd",usersKey,userid);
end
return 1;
```



##### 11.2.4.3.如何在项目中使用Lua脚本

创建SecKill_redisByScript类

**代码实例：**

```java
package com.atguigu;

import java.io.IOException;
import java.util.HashSet;
import java.util.Set;

import org.slf4j.LoggerFactory;
import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;

/**
 * 使用Lua脚本
 */
public class SecKill_redisByScript {

    private static final org.slf4j.Logger logger = LoggerFactory.getLogger(SecKill_redisByScript.class);

    public static void main(String[] args) {
        JedisPool jedispool = JedisPoolUtil.getJedisPoolInstance();

        Jedis jedis = jedispool.getResource();
        System.out.println(jedis.ping());

        Set<HostAndPort> set = new HashSet<HostAndPort>();

        //	doSecKill("201","sk:0101");
    }

    /**
     * Lua脚本
     */
    static String secKillScript = "local userid=KEYS[1];\r\n" +
            "local prodid=KEYS[2];\r\n" +
            "local qtkey='sk:'..prodid..\":qt\";\r\n" +
            "local usersKey='sk:'..prodid..\":usr\";\r\n" +
            "local userExists=redis.call(\"sismember\",usersKey,userid);\r\n" +
            "if tonumber(userExists)==1 then \r\n" +
            "   return 2;\r\n" +
            "end\r\n" +
            "local num= redis.call(\"get\" ,qtkey);\r\n" +
            "if tonumber(num)<=0 then \r\n" +
            "   return 0;\r\n" +
            "else \r\n" +
            "   redis.call(\"decr\",qtkey);\r\n" +
            "   redis.call(\"sadd\",usersKey,userid);\r\n" +
            "end\r\n" +
            "return 1";

    static String secKillScript2 =
            "local userExists=redis.call(\"sismember\",\"{sk}:0101:usr\",userid);\r\n" +
                    " return 1";

    public static boolean doSecKill(String uid, String prodid) throws IOException {

        //redis连接池
        JedisPool jedispool = JedisPoolUtil.getJedisPoolInstance();
        Jedis jedis = jedispool.getResource();

        //jedis.scriptLoad方法加载Lua脚本
        String sha1 = jedis.scriptLoad(secKillScript);
        Object result = jedis.evalsha(sha1, 2, uid, prodid);

        String reString = String.valueOf(result);
        if ("0".equals(reString)) {
            System.err.println("已抢空！！");
        } else if ("1".equals(reString)) {
            System.out.println("抢购成功！！！！");
        } else if ("2".equals(reString)) {
            System.err.println("该用户已抢过！！");
        } else {
            System.err.println("抢购异常！！");
        }
        jedis.close();
        return true;
    }
}
```

修改SecKillServlet类中的doPost方法，使用使用Lua脚本方法。

```java
package com.atguigu;

import java.io.IOException;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.Random;

import javax.servlet.ServletException;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import javax.xml.ws.soap.AddressingFeature.Responses;

/**
 * 秒杀案例
 */
public class SecKillServlet extends HttpServlet {
    private static final long serialVersionUID = 1L;

    public SecKillServlet() {
        super();
    }

    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {

        String userid = new Random().nextInt(50000) + "";
        String prodid = request.getParameter("prodid");

        //boolean isSuccess=SecKill_redis.doSecKill(userid,prodid);

        //使用Lua脚本
        boolean isSuccess = SecKill_redisByScript.doSecKill(userid, prodid);
        response.getWriter().print(isSuccess);
    }

}
```



## 12.Redis持久化之RDB

Redis 提供了2个不同形式的持久化方式。

- RDB（Redis DataBase）
- AOF（Append Of File）



### 12.1.RDB（Redis DataBase）



**RDB是什么：**

在指定的**时间间隔**内将内存中的**数据集快照**写入磁盘， 也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里



### 12.2.备份是如何执行的

Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。**RDB的缺点是最后一次持久化后的数据可能丢失**。



### 12.3.Fork

- Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程
- 在Linux程序中，fork()会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，Linux中引入了“**写时复制技术**”
- **一般情况父进程和子进程会共用同一段物理内存**，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。



### 12.4.RDB持久化流程

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202172018.png)



![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218093639.png)

**RDB底层过程：**

redis内存要进行持久化，持久化之后最终会生出一个文件，文件名称是**dump.rdb**，RDB持久化的内容会写在dump.rdb文件中去。redis内存内容并不是直接写到dump.rdb文件中。它的过程是首先在持久化过程中创建一个子进程，子进程名字叫fork。当它持久化过程中会创建一个临时区域文件，把redis内存内容同步到临时区域文件，当同步之后再把临时区域文件内容覆盖到dump.rdb文件中。

**为什么不能直接把redis内存内容同步到dump.rdb文件中，而需要一个临时区域文件？**

redis数据要记录某一点的快照同步到dump.rdb中去，首先到临时区域文件中，假如有10个key，同步到第8个key的时候，突然服务器挂掉了，如果直接同步到dump.rdb，会造成数据不完整。所以先把数据同步到临时区域文件中，等同步好后，再去替换dump.rdb文件，这样做保证数据的一致性和完整性，也是为了数据的安全考虑。



### 12.5.redis.conf配置参数说明

#### 12.5.1.dump.rdb参数

在redis.conf中配置文件名称，默认为dump.rdb。在启动redis时，redis的启动目录下会生成一个dump.rdb文件。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218094222.png)



#### 12.5.2.stop-writes-on-bgsave-error参数

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218095046.png)

当Redis无法写入磁盘的话，直接关掉Redis的写操作。推荐yes。



#### 12.5.3.rdbcompression压缩文件

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218095305.png)

对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。

如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。推荐yes。



#### 12.5.4.rdbchecksum检查完整性

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218095421.png)

在存储快照后，还可以让redis使用CRC64算法来进行数据校验，

但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。推荐yes。



#### 12.5.5 Save

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218095914.png)

格式：save 秒钟 写操作次数

RDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件，**默认是1分钟内改了1万次，或5分钟内改了10次，或15分钟内改了1次。**

禁用

不设置save指令，或者给save传入空字符串



**演示save持久化过程：**

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218100743.png)

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218101826.png)

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/20220218101716.png)

**步骤：**

1. 修改redis.conf中的save配置，`save 20 3`，每20秒内有大于等于3个key发生变化，进行持久化。
2. 查看当前dump.rdb文件大小。如果进行了持久化，那么该文件会变大。
3. 使用命令存放redis数据
4. 等待20秒查看dump.rdb文件大小



#### 12.5.6.命令save VS bgsave

save ：save时只管保存，其它不管，全部阻塞。手动保存。不建议。

bgsave：Redis会在后台异步进行快照操作， 快照同时还可以响应客户端请求。

可以通过lastsave 命令获取最后一次成功执行快照的时间



#### 12.5.7.flushall命令

执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义



### 12.6. rdb的备份

1. 将dump.rdb拷贝一份，
2. 然后再关闭Redis
3. 将备份的dump.rdb文件移到redis启动目录下
4. 启动redis，备份数据会直接加载



### 12.7.优势

- 适合大规模的数据恢复
- 对数据完整性和一致性要求不高更适合使用
- 节省磁盘空间
- 恢复速度快

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202181020.png)



### 12.8.劣势

- Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑
- 虽然Redis在fork时使用了**写时拷贝技术**,但是如果数据庞大时还是比较消耗性能。
- 在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。



## 13.Redis持久化之AOF

### 13.1.AOF（Append Only File）

AOP是以日志的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来(读操作不记录)， 只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。



#### 13.1.1.AOF持久化流程

1. 客户端的请求写命令会被append追加到AOF缓冲区内；

2. AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中；

3. AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量；

4. Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的

   ![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202181349.png)



#### 13.1.2.AOF默认

**AOF默认不开启**

可以在redis.conf中配置文件名称，默认为 appendonly.aof

AOF文件的保存路径，同RDB的路径一致。



#### 13.1.3.AOF和RDB同时开启，redis听谁的？

AOF和RDB同时开启，系统默认取AOF的数据（数据不会存在丢失）



#### 13.1.4.AOF启动/修复/恢复

- AOF的备份机制和性能虽然和RDB不同, 但是备份和恢复的操作同RDB一样，都是拷贝备份文件，需要恢复时再拷贝到Redis工作目录下，启动系统即加载。
- 正常恢复
  - 修改默认的appendonly no，改为yes
  - 修改默认的appendonly no，改为yes
  - 恢复：重启redis然后重新加载
- 异常恢复
  - 修改默认的appendonly no，改为yes
  - 如遇到AOF文件损坏，通过/usr/local/bin/redis-check-aof--fix appendonly.aof进行恢复
  - 备份被写坏的AOF文件
  - 恢复：重启redis，然后重新加载



#### 13.1.5.AOF同步频率设置

appendfsync always
始终同步，每次Redis的写入都会立刻记入日志；性能较差但数据完整性比较好

appendfsync everysec
每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。

appendfsync no
redis不主动进行同步，把同步时机交给操作系统。



#### 13.1.6.Rewrite压缩

AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制, 当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集.可以使用命令bgrewriteaof

**重写原理，如何实现重写：**

AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，redis4.0版本后的重写，是指上就是把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作。

no-appendfsync-on-rewrite：

如果 no-appendfsync-on-rewrite=yes ,不写入aof文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能）

如果 no-appendfsync-on-rewrite=no,  还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。（数据安全，但是性能降低）
**触发机制，何时重写：**
Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发
重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此设定Redis要满足一定条件才会进行重写。 
auto-aof-rewrite-percentage：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发）
auto-aof-rewrite-min-size：设置重写的基准值，最小文件64MB。达到这个值开始重写。
例如：文件达到70MB开始重写，降到50MB，下次什么时候开始重写？100MB
系统载入时或者上次重写完毕时，Redis会记录此时AOF大小，设为base_size,
如果Redis的AOF当前大小>= base_size +base_size*100% (默认)且当前大小>=64mb(默认)的情况下，Redis会对AOF进行重写。

**重写流程：**

1. bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。
2. 主进程fork出子进程执行重写操作，保证主进程不会阻塞。
3. 子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。
4. 1. 子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。
   2. 主进程把aof_rewrite_buf中的数据写入到新的AOF文件。
5. 使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202181359.png)



#### 13.1.7.优势

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202181401.png)

- 备份机制更稳健，丢失数据概率更低。
- 可读的日志文本，通过操作AOF稳健，可以处理误操作。



#### 13.1.8.劣势

- 比起RDB占用更多的磁盘空间。
- 恢复备份速度要慢。
- 每次读写都同步的话，有一定的性能压力。
- 存在个别Bug，造成恢复不能。



#### 13.1.9.  小总结

![](https://gitee.com/Amazjing/markdown-img/raw/master/img/202202181403.png)



## 14.RDB与AOF哪个好

官方推荐两个都启用。

如果对数据不敏感，可以选单独用RDB。

不建议单独用 AOF，因为可能会出现Bug。

如果只是做纯内存缓存，可以都不用。

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储

- AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾. 

- Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大

- 只做缓存：如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.

- 同时开启两种持久化方式

- 在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据, 因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.

- RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 

- 建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)， 快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。

- 性能建议

  因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果使用AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价,一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。



